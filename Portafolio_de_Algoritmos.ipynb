{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Portafolio de Algoritmos.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SergioVinicio/Elements-of-machine-Learning/blob/master/Portafolio_de_Algoritmos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ9tAz8PreAy",
        "colab_type": "text"
      },
      "source": [
        "# Objetivo\n",
        "\n",
        "El presente documento es una recopilación de funciones, lineas de código para gráficas,  algoritmos, ciclos y más que se fueron juntando a lo largo del curso de \"Elements of machine learning\" en la Universidad Francisco Marroquín. El objetivo de este documento es servir como referencia personal y para demas personas a la hora de limpiar y analizar datos. Además de esto, también hay una recopilación de líneas de código necesarias para correr algoritmos predictivos. Cabe destacar que todo que se presenta a continuación fue corrido y probado en Google Colab. Y tambien se reitera que en las funciones en vez de poner el dataset que se uso hay comentarios sobre que tipo de objeto se pone, esto con el fin de adaptarse a cualquier necesidad."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhroE7uFagXN",
        "colab_type": "text"
      },
      "source": [
        "#Librerias Fundamentales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSsekdjzajcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statsmodels\n",
        "import statsmodels.formula.api as smf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import patsy\n",
        "from patsy import dmatrix\n",
        "import sklearn\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K92-VPq5TsKJ",
        "colab_type": "text"
      },
      "source": [
        "# Cargar y analisis fundamental de Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZdQXp2jT-fM",
        "colab_type": "text"
      },
      "source": [
        "Con la siguiente línea de código se pueden subir archivos desde la computadora en que se este trabajando a Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFgi9MYFq7uP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files \n",
        "upload = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqfOrNcUU0Z3",
        "colab_type": "text"
      },
      "source": [
        "Y a continuación se presenta como guardar como un dataframe el archivo cargado, suponiendo que el archivo subido esta en formato .csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v518eO5vUvTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"Nombre del archivo\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "li_I7jQtVFru",
        "colab_type": "text"
      },
      "source": [
        "Al guardar como un dataframe de pandas el archivo csv podemos hacer uso de varios comandos como .describe(), .head() y demas para entender y estudiar un poco mejor los datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ojiinqw2VF_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Describe grandes rasgos de los datos\n",
        "df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jnPdI0vXPYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Muestra las primeras filas del dataframe\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNFrOzsjXS38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Crea un histograme de la columna seleccionada, dentro de \"\" se pone el nombre de la columna\n",
        "df.hist('Nombre de la columna dentro del dataset')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jqw45GAvXWE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Matriz de correlacion\n",
        "print(df.corr())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvq_d7-vXW5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Mostrar la matriz de correlación de una manera mas visual y estetica\n",
        "cols = list(df)\n",
        "sns.set(font_scale=.75)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15,15))\n",
        "sns.heatmap(df.corr(), ax=ax, cbar=True, annot=True, fmt=\".2f\", square=True, yticklabels=cols, xticklabels=cols)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuE3R6E6e39u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generemos datos a partir de una función senoidal\n",
        "import random\n",
        "from matplotlib.pylab import rcParams\n",
        "\n",
        "#Tomemos ángulos de 0 a 300\n",
        "x = np.array([i*np.pi/180 for i in range(0,300,4)])\n",
        "np.random.seed(10)  #El error aleatorio será reproducible\n",
        "y = np.sin(x) + np.random.normal(0,0.15,len(x))\n",
        "data = pd.DataFrame(np.column_stack([x,y]),columns=['x','y'])\n",
        "plt.plot(data['x'],data['y'],'.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTj28v93eU97",
        "colab_type": "text"
      },
      "source": [
        "#Funciones Utiles para analisis, limpieza o visualizacion de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NOuFJzyee2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Se cambia el valor de una columna o se hace una nueva columna, basado en otra columna, se haria una columna de falsos o verdaderos basado en la condicion especificada\n",
        "data['mpg01'] = (data['mpg'] > data['mpg'].median()).astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qjpc8zVeYR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Con este codigo se grafica un histograma de cada una de las variables del dataset\n",
        "data.hist(figsize=(15,20));\n",
        "plt.figure();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA1V6UIRe811",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Matriz de dispersion de cada variable del dataset\n",
        "pd.plotting.scatter_matrix(data,figsize=(10,10))\n",
        "plt.figure();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSPhVBafE8-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Con esta funcion se puede observar en una grafica de barras como se distribuyen los datos, yo lo uso principalmente para chequear si son binarios los datos\n",
        "sns.countplot(x='Clase',data=bc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqxQTKqbFrdF",
        "colab_type": "text"
      },
      "source": [
        "El codigo de abajo es un ejemplo con data de titanic, esta funcion sirve para visualizar, los datos y aparte agruparlos. En este caso el eje exe representaria la clase del pasajero, y el eje y contabilizaria cuantos sobrevivieron de cada clase, por lo que en cada tipo de clase saldria una barra representando quien sobrevive y quie no. Muy util para tener una idea de como se comportan los datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-F5teh1FqFC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.countplot('Pclass', hue='Survived', data=train)\n",
        "plt.title('Pclass: Survived vs Dead')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOmBelpRGqsZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Trazar relaciones de pares en un conjunto de datos.\n",
        "#De forma predeterminada, esta función creará una cuadrícula de Ejes de manera que cada variable en los datos se comparta en el eje y en una sola fila y\n",
        "#en el eje x en una sola columna. Los ejes diagonales se tratan de manera diferente, dibujando una gráfica para mostrar \n",
        "#la distribución univariada de los datos para la variable en esa columna.\n",
        "#También es posible mostrar un subconjunto de variables o trazar diferentes variables en las filas y columnas.\n",
        "Fuente: https://seaborn.pydata.org/generated/seaborn.pairplot.html  \n",
        "sns.pairplot(train, hue=\"Sex\");"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbBQYZr6YFxs",
        "colab_type": "text"
      },
      "source": [
        "#Modelos de machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86SdpPKtFvid",
        "colab_type": "text"
      },
      "source": [
        "**Pasos a la hora de querer crear un modelo de machine learning**\n",
        "\n",
        "1.) State the question and determine required data\n",
        "\n",
        "2.) Acquire the data in an accessible format\n",
        "\n",
        "3.) Identify and correct missing data points/anomalies as required\n",
        "\n",
        "4.) Prepare the data for the machine learning model\n",
        "\n",
        "5.) Establish a baseline model that you aim to exceed\n",
        "\n",
        "6.) Train the model on the training data\n",
        "\n",
        "7.) Make predictions on the test data\n",
        "\n",
        "8.) Compare predictions to the known test set targets and calculate performance metrics\n",
        "\n",
        "9.) If performance is not satisfactory, adjust the model, acquire more data, or try a different modeling  technique\n",
        "\n",
        "10.) Interpret model and report results visually and numerically.\n",
        "\n",
        "**Fuente:** https://towardsdatascience.com/random-forest-in-python-24d0893d51c0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OI-elgloYScu",
        "colab_type": "text"
      },
      "source": [
        "En la mayoría de los problemas ya sea de regresión o clasificación se busca dividir los datos en 2 conjuntos, uno para entrenar el modelo y otro para validar como le iría  al modelo con datos que se desconoce, es por eso que se busca dividir al conjunto de datos en 2 subconjuntos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz4DudXeYopk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Librería y función necesaria para dividir los datos, \"test_size\" define el porcentaje que irá a datos de prueba\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\"Los que servirán como predictores\", \"La variable a predecir\", test_size=0.25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHX5S39ccgBN",
        "colab_type": "text"
      },
      "source": [
        "Ya creados los conjuntos de entrenamiento y prueba, ahora podemos poner a prueba distintos modelos. A continuacion se muestra la forma simple de usar estos modelos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cjih7GGecy6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Paquetes necesarios para realizar una regresión logistica, discriminante lineal y discriminante cuadratico\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkCeZ5c7Daid",
        "colab_type": "text"
      },
      "source": [
        "**Regresion Lineal Simple**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuByS4MyDdDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Esta funcion es muy util, porque muestra una regresion lineal simple graficamente y muestra sus intervalos de confianza\n",
        "sns.regplot(x='Variable 1', y='Variable 2', data= data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-5es-KwBSlY",
        "colab_type": "text"
      },
      "source": [
        "**Regresion Lineal Multiple**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3V-91hG7BRu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Este es un ejemplo de como usar una regresion lineal multiple\n",
        "regresion= smf.ols(formula=\"variabledependiente ~ V1+V2+V3...+Vn\", data=data).fit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32K_wHtDnzjm",
        "colab_type": "text"
      },
      "source": [
        "**Regresión Logistica**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsGyonNacvlZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logreg = LogisticRegression()\n",
        "rfe = RFE(logreg, 20)\n",
        "rfe = rfe.fit(X_train, Y_train)\n",
        "logit_model=sm.Logit(Y_train,X_train)\n",
        "result=logit_model.fit()\n",
        "Y_pred = logreg.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7pbW93CFRvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Otra forma de hacer regresion logistica y sus respectivas metricas\n",
        "est = smf.Logit(data['V1'], data[data.columns[0:5]]).fit()\n",
        "est.summary2()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rem0-TB3dIFN",
        "colab_type": "text"
      },
      "source": [
        "**LDA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWjOUN7jdL7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda = LinearDiscriminantAnalysis().fit(X_train, Y_train)\n",
        "Y_pred2= lda.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqX1PdAcdRmo",
        "colab_type": "text"
      },
      "source": [
        "**QDA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0IS3MPjdQW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "qda = QuadraticDiscriminantAnalysis()\n",
        "model2 = qda.fit(X_train, Y_train)\n",
        "pred2=model2.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdccpDqpddtL",
        "colab_type": "text"
      },
      "source": [
        "**KNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mXlxhTqddEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=20)\n",
        "knn.fit(X_train, Y_train)\n",
        "y_predicho = knn.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk76AHgWN2iu",
        "colab_type": "text"
      },
      "source": [
        "**Como separar un grupo de datos**\n",
        "\n",
        "Imagina que tenemos una muestra de 6 observaciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SteRvJvyN4vm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.array([1,2,3,4,5,6])\n",
        "kfold = KFold(3,True,1) #Recuerda que puedes revisar la documentación de nuevas funciones usando Tab luego del primer paréntesis\n",
        "splitdata = kfold.split(data) # Esta función genera listas de índices separadas como indicado\n",
        "for train, test in splitdata:\n",
        "  # imprimo en la línea 'split' los índices train y test que generó kfold.split\n",
        "  print('split %s, %s\\ntrain: %s, test: %s' % (train,test,data[train], data[test]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEjM5YuXOMhY",
        "colab_type": "text"
      },
      "source": [
        "**Algoritmo completo para aplicar la validacion cruzada**\n",
        "\n",
        "Este ejemplo debe servir como base, para problemas mas complejos solo hace falta adpatar este mismo codigo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJdknVoEOYzT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.array(([1,2,3,4,5,6],[0.1,0.2,0.3,0.4,0.5,0.6]))\n",
        "# Pasos 1 y 2 ocurren en la siguiente línea\n",
        "kfold = KFold(3,True,1)\n",
        "# Paso 3 ocurre al usar split\n",
        "splitdata = kfold.split(X = data[0], y = data[1])\n",
        "RMSE_i = [] # Aquí es donde guardaré mi medida de varianza para cada modelo\n",
        "for train, test in splitdata:\n",
        "  # 4. Ajustar una regresión logística en un grupo de entrenamiento\n",
        "  model = smf.Logit(data[1][train], data[0][train]).fit()\n",
        "  # 5. Evaluar en el grupo de entrenamiento\n",
        "  y_hat = model.predict(data[0][test])\n",
        "  # 6. Guardar una medida de habilidad del modelo\n",
        "  RMSE_i.append((sum((y_hat - data[1][test])**2)/len(y_hat))**(1/2))\n",
        "  # Al repetir el loop, descartamos el modelo y repetimos los pasos para otro split\n",
        "  \n",
        "RMSE = np.mean(RMSE_i)\n",
        "print(RMSE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfbCEiXZdYRk",
        "colab_type": "text"
      },
      "source": [
        "**Ejemplo de como aplicar bootstrap**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYZ6L2kvdbfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "mean = [0,0]\n",
        "cov = [[1.,0.25],[0.25,1.25]]\n",
        "\n",
        "# Generamos observaciones (X,Y) a partir de una distribución aleatoria\n",
        "np.random.seed(1)\n",
        "X, Y = np.random.multivariate_normal(mean, cov, 100).T\n",
        "X = X.reshape(-1, 1)\n",
        "Y = Y.reshape(-1, 1)\n",
        "\n",
        "alphas_hat = []\n",
        "\n",
        "for _ in range(1000):\n",
        "  X1, Y1 = resample(X, Y, replace=True, n_samples=100)\n",
        "  [s_X, s_XY, _, s_Y] = np.cov(X1.T, Y1.T).reshape(-1, 1)\n",
        "  alphas_hat.append(float((s_Y-s_XY)/(s_X+s_Y-2*s_XY)))\n",
        "\n",
        "alpha_mean = np.mean(alphas_hat)\n",
        "alpha_err = np.std(alphas_hat, ddof=1)\n",
        "print(alpha_mean, alpha_err)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d3xj75seFIw",
        "colab_type": "text"
      },
      "source": [
        "**Ridge Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcATXKpWeIp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "reg = linear_model.Ridge(alpha=1)\n",
        "reg.fit(X_train, Y_train)\n",
        "RMSE = sqrt(mean_squared_error(Y_test, reg.predict(X_test)))\n",
        "RMSE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VThq0lYEfaWl",
        "colab_type": "text"
      },
      "source": [
        "**Boosting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7YNQfzQfZpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "model = GradientBoostingClassifier()\n",
        "model.fit(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCdFZvpQgFGh",
        "colab_type": "text"
      },
      "source": [
        "**K-Mean Clustering**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcycErLpgG4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_it5--4QiknN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clusters = 7\n",
        "kmeans = KMeans(n_clusters = clusters) \n",
        "kmeans.fit(data) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQzOfw1tiuQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sse = {}\n",
        "for k in range(1, 15):\n",
        "    kmeans = KMeans(n_clusters=k).fit(data)\n",
        "    data[\"clusters\"] = kmeans.labels_\n",
        "    sse[k] = kmeans.inertia_ # Inertia: Sum of distances of samples to their closest cluster center\n",
        "plt.figure()\n",
        "plt.plot(list(sse.keys()), list(sse.values()))\n",
        "plt.xlabel(\"Number of cluster\")\n",
        "plt.ylabel(\"SSE\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4ygvU0niy36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kmeans.cluster_centers_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9do2KuydZXga",
        "colab_type": "text"
      },
      "source": [
        "#Metricas para evaluar modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AvV6WIRZ3Ud",
        "colab_type": "text"
      },
      "source": [
        "Es importante tener a la mano siempre métricas para medir el desempeño de nuestros modelos hechos, por lo que a continuación se muestran algunas de las que mas he usado. Hay mas para clasificacion en este espacio, porque la mayoria de regresion estan descritar arribas. Ademas de eso, con .summary() se obtienen las mayorias de las metricas en los modelos de regresion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxWazibmj-jD",
        "colab_type": "text"
      },
      "source": [
        "**Regresion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsVqzTRMZf77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Error cuadratico medio\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#En el primer argumento se ponen las Y que tenemos del test set y en la otra la predicción del modelo con las X del test set.\n",
        "mse_test = mean_squared_error(Y_test, pred_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh1a2qp9CPXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Con summary observamos un resumen completo de las metricas para evaluar una regresion lineal multiple y otras\n",
        "print(regresion.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alXmn0QDj7JX",
        "colab_type": "text"
      },
      "source": [
        "**Clasificacion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c50KFu1Oc12y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTTc3Teaja6B",
        "colab_type": "text"
      },
      "source": [
        "En la siguiente línea de código tenemos un reporte de clasificación, el mismo se usa para evaluar modelos de clasificación. Para hacer uso de esto solo hay que importar classification_report de sklearn.metrics. Como parametros para la función ponemos de primero nuestra Y para prueba, seguido de nuestras predicciones, y el parametro de digits es para ver los decimales que se mostrarán."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65EanlxNfpHi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(Y_test, pred, digits=3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2rfkwAPkKdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(valores reales, valores predichos)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9oJMj4wkOxB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(valores reales, valores predichos)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNirQBMhkYOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import recall_score\n",
        "recall_score(valores reales, valores predichos)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbVa6F_PkdT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_score\n",
        "precision_score(valores reales, valores predichos)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxx15q9tkhyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(valores reales, valores predichos)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NJ4QH16krXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "fpr_RF, tpr_RF, thresholds_RF = roc_curve(df.actual_label.values, df.model_RF.values)\n",
        "fpr_LR, tpr_LR, thresholds_LR = roc_curve(df.actual_label.values, df.model_LR.values)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(fpr_RF, tpr_RF,'r-',label = 'RF')\n",
        "plt.plot(fpr_LR,tpr_LR,'b-', label= 'LR')\n",
        "plt.plot([0,1],[0,1],'k-',label='random')\n",
        "plt.plot([0,0,1,1],[0,1,1,1],'g-',label='perfect')\n",
        "plt.legend()\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aFgoI3woQFc",
        "colab_type": "text"
      },
      "source": [
        "**Referencias extras**\n",
        "\n",
        "\n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2016/02/7-important-model-evaluation-error-metrics/\n",
        "\n",
        "https://towardsdatascience.com/random-forest-in-python-24d0893d51c0\n",
        "\n",
        "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
        "\n",
        "https://medium.com/@hjhuney/implementing-a-random-forest-classification-model-in-python-583891c99652\n",
        "\n",
        "https://www.geeksforgeeks.org/multiclass-classification-using-scikit-learn/\n",
        "\n",
        "https://swcarpentry.github.io/python-novice-inflammation/06-func/index.html"
      ]
    }
  ]
}
